name: "Scrape DBD Wiki & save it to Supabase every week on sunday"

on: workflow_dispatch
# on:
#   schedule:
#     - cron: "0 0 * * 0"

jobs:
  scrape-and-save:
    runs-on: ubuntu-latest

    steps:
      # Paso 1: Clonar el repositorio
      - name: Checkout repository
        uses: actions/checkout@v3

      # Paso 2: Configurar Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "20"

      - name: Install system dependencies
        run: sudo apt-get update && sudo apt-get install -y libnss3 libatk-bridge2.0-0 libxcomposite1 libxdamage1 libxrandr2 libgbm-dev

      # Paso 3: Instalar dependencias
      - name: Install dependencies
        run: npm install
      - name: Download browsers for Playwright
        run: sudo npx playwright install --with-deps

      - name: Set environment variables
        run: |
          echo "API_URL=${{ secrets.API_URL }}" >> $GITHUB_ENV
          echo "API_KEY=${{ secrets.API_KEY }}" >> $GITHUB_ENV

      # Paso 4: Ejecutar el script
      - name: Run the script
        run: node index.mjs
        env:
          API_URL: ${{ secrets.API_URL }}
          API_KEY: ${{ secrets.API_KEY }}
