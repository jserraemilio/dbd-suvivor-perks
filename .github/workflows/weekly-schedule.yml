name: "Scrape DBD Wiki & save it to Supabase every week on sunday"

on: workflow_dispatch
# on:
#   schedule:
#     - cron: "0 0 * * 0"

jobs:
  scrape-and-save:
    runs-on: ubuntu-latest

    steps:
      # Paso 1: Clonar el repositorio
      - name: Checkout repository
        uses: actions/checkout@v3

      # Paso 2: Configurar Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "18"

      # Paso 3: Instalar dependencias
      - name: Install dependencies
        run: npm install

      - name: Set environment variables
        run: |
          echo "API_URL=${{ secrets.API_URL }}" >> $GITHUB_ENV
          echo "API_KEY=${{ secrets.API_KEY }}" >> $GITHUB_ENV

      # Paso 4: Ejecutar el script
      - name: Run the script
        run: node ./index.jms
        env:
          API_URL: ${{ secrets.API_URL }}
          API_KEY: ${{ secrets.API_KEY }}
